{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext.getOrCreate() \n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contents of the imageToPixels.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imageToPixels import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[209, 211, 210],\n",
      "        [210, 212, 211],\n",
      "        [204, 206, 205],\n",
      "        ..., \n",
      "        [180, 180, 180],\n",
      "        [146, 146, 146],\n",
      "        [143, 143, 143]],\n",
      "\n",
      "       [[210, 212, 211],\n",
      "        [217, 219, 218],\n",
      "        [215, 217, 216],\n",
      "        ..., \n",
      "        [126, 126, 126],\n",
      "        [126, 126, 126],\n",
      "        [115, 115, 115]],\n",
      "\n",
      "       [[212, 214, 213],\n",
      "        [223, 225, 224],\n",
      "        [225, 227, 226],\n",
      "        ..., \n",
      "        [124, 124, 124],\n",
      "        [135, 135, 135],\n",
      "        [122, 122, 122]],\n",
      "\n",
      "       ..., \n",
      "       [[121, 120, 125],\n",
      "        [124, 123, 128],\n",
      "        [146, 146, 148],\n",
      "        ..., \n",
      "        [122, 120, 121],\n",
      "        [127, 125, 126],\n",
      "        [126, 124, 125]],\n",
      "\n",
      "       [[134, 133, 138],\n",
      "        [162, 161, 166],\n",
      "        [200, 200, 202],\n",
      "        ..., \n",
      "        [147, 145, 146],\n",
      "        [135, 133, 134],\n",
      "        [115, 113, 114]],\n",
      "\n",
      "       [[135, 134, 139],\n",
      "        [155, 154, 159],\n",
      "        [158, 158, 160],\n",
      "        ..., \n",
      "        [196, 194, 195],\n",
      "        [164, 162, 163],\n",
      "        [119, 117, 118]]], dtype=uint8), array([[[115,  34,  43],\n",
      "        [110,  29,  38],\n",
      "        [102,  22,  31],\n",
      "        ..., \n",
      "        [ 50,  12,   3],\n",
      "        [ 52,  14,   5],\n",
      "        [ 53,  15,   6]],\n",
      "\n",
      "       [[128,  41,  49],\n",
      "        [123,  36,  44],\n",
      "        [117,  30,  38],\n",
      "        ..., \n",
      "        [ 63,  15,   5],\n",
      "        [ 64,  16,   6],\n",
      "        [ 65,  17,   7]],\n",
      "\n",
      "       [[148,  49,  52],\n",
      "        [144,  45,  48],\n",
      "        [136,  40,  42],\n",
      "        ..., \n",
      "        [ 84,  18,   6],\n",
      "        [ 85,  19,   7],\n",
      "        [ 86,  20,   8]],\n",
      "\n",
      "       ..., \n",
      "       [[ 36, 112,  65],\n",
      "        [ 36, 112,  65],\n",
      "        [ 37, 113,  66],\n",
      "        ..., \n",
      "        [ 59, 128,  74],\n",
      "        [ 60, 129,  75],\n",
      "        [ 60, 129,  75]],\n",
      "\n",
      "       [[ 36, 112,  65],\n",
      "        [ 36, 112,  65],\n",
      "        [ 37, 113,  66],\n",
      "        ..., \n",
      "        [ 56, 125,  71],\n",
      "        [ 58, 127,  73],\n",
      "        [ 58, 127,  73]],\n",
      "\n",
      "       [[ 36, 112,  65],\n",
      "        [ 36, 112,  65],\n",
      "        [ 37, 113,  66],\n",
      "        ..., \n",
      "        [ 55, 124,  70],\n",
      "        [ 56, 125,  71],\n",
      "        [ 57, 126,  72]]], dtype=uint8), array([[[ 36,  26,  25],\n",
      "        [ 36,  26,  25],\n",
      "        [ 36,  26,  25],\n",
      "        ..., \n",
      "        [ 69,  55,  42],\n",
      "        [ 70,  64,  48],\n",
      "        [ 73,  74,  56]],\n",
      "\n",
      "       [[ 37,  27,  26],\n",
      "        [ 37,  27,  26],\n",
      "        [ 37,  27,  26],\n",
      "        ..., \n",
      "        [ 72,  56,  43],\n",
      "        [ 72,  66,  50],\n",
      "        [ 79,  80,  62]],\n",
      "\n",
      "       [[ 38,  28,  27],\n",
      "        [ 38,  28,  27],\n",
      "        [ 38,  28,  27],\n",
      "        ..., \n",
      "        [ 77,  61,  48],\n",
      "        [ 75,  69,  53],\n",
      "        [ 76,  77,  59]],\n",
      "\n",
      "       ..., \n",
      "       [[ 61,  51,  50],\n",
      "        [ 55,  45,  44],\n",
      "        [ 53,  43,  42],\n",
      "        ..., \n",
      "        [255, 214, 196],\n",
      "        [242, 195, 179],\n",
      "        [248, 196, 182]],\n",
      "\n",
      "       [[ 58,  48,  47],\n",
      "        [ 51,  41,  40],\n",
      "        [ 50,  40,  39],\n",
      "        ..., \n",
      "        [255, 212, 194],\n",
      "        [240, 187, 173],\n",
      "        [243, 185, 173]],\n",
      "\n",
      "       [[ 38,  28,  27],\n",
      "        [ 31,  21,  20],\n",
      "        [ 31,  21,  20],\n",
      "        ..., \n",
      "        [255, 211, 194],\n",
      "        [238, 182, 169],\n",
      "        [238, 176, 165]]], dtype=uint8), array([[[251, 251, 251],\n",
      "        [245, 245, 245],\n",
      "        [154, 154, 154],\n",
      "        ..., \n",
      "        [ 67,  67,  67],\n",
      "        [ 78,  78,  78],\n",
      "        [ 87,  87,  87]],\n",
      "\n",
      "       [[250, 250, 250],\n",
      "        [255, 255, 255],\n",
      "        [173, 173, 173],\n",
      "        ..., \n",
      "        [ 61,  61,  61],\n",
      "        [ 70,  70,  70],\n",
      "        [ 77,  77,  77]],\n",
      "\n",
      "       [[234, 234, 234],\n",
      "        [255, 255, 255],\n",
      "        [193, 193, 193],\n",
      "        ..., \n",
      "        [ 53,  53,  53],\n",
      "        [ 59,  59,  59],\n",
      "        [ 64,  64,  64]],\n",
      "\n",
      "       ..., \n",
      "       [[ 20,  20,  20],\n",
      "        [ 17,  17,  17],\n",
      "        [ 15,  15,  15],\n",
      "        ..., \n",
      "        [ 41,  41,  41],\n",
      "        [ 90,  90,  90],\n",
      "        [130, 130, 130]],\n",
      "\n",
      "       [[ 20,  20,  20],\n",
      "        [ 17,  17,  17],\n",
      "        [ 16,  16,  16],\n",
      "        ..., \n",
      "        [  7,   7,   7],\n",
      "        [ 19,  19,  19],\n",
      "        [ 36,  36,  36]],\n",
      "\n",
      "       [[ 21,  21,  21],\n",
      "        [ 18,  18,  18],\n",
      "        [ 17,  17,  17],\n",
      "        ..., \n",
      "        [ 11,  11,  11],\n",
      "        [  4,   4,   4],\n",
      "        [  4,   4,   4]]], dtype=uint8), array([[[171, 145, 108],\n",
      "        [171, 145, 108],\n",
      "        [171, 145, 108],\n",
      "        ..., \n",
      "        [255, 249, 247],\n",
      "        [255, 249, 247],\n",
      "        [255, 249, 247]],\n",
      "\n",
      "       [[171, 147, 111],\n",
      "        [171, 147, 111],\n",
      "        [171, 147, 111],\n",
      "        ..., \n",
      "        [255, 249, 246],\n",
      "        [255, 249, 246],\n",
      "        [255, 249, 246]],\n",
      "\n",
      "       [[169, 145, 111],\n",
      "        [169, 145, 111],\n",
      "        [169, 145, 111],\n",
      "        ..., \n",
      "        [255, 250, 246],\n",
      "        [255, 250, 246],\n",
      "        [255, 250, 246]],\n",
      "\n",
      "       ..., \n",
      "       [[ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        ..., \n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101]],\n",
      "\n",
      "       [[ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        ..., \n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101]],\n",
      "\n",
      "       [[ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        [ 35,  36,  41],\n",
      "        ..., \n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101],\n",
      "        [ 79,  85, 101]]], dtype=uint8), array([[[ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        ..., \n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51]],\n",
      "\n",
      "       [[ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        ..., \n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51]],\n",
      "\n",
      "       [[ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        [ 83,  94,  77],\n",
      "        ..., \n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51],\n",
      "        [ 64,  77,  51]],\n",
      "\n",
      "       ..., \n",
      "       [[152, 146, 134],\n",
      "        [152, 146, 134],\n",
      "        [152, 146, 134],\n",
      "        ..., \n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127]],\n",
      "\n",
      "       [[153, 145, 134],\n",
      "        [153, 145, 134],\n",
      "        [153, 145, 134],\n",
      "        ..., \n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127]],\n",
      "\n",
      "       [[153, 145, 134],\n",
      "        [153, 145, 134],\n",
      "        [153, 145, 134],\n",
      "        ..., \n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127],\n",
      "        [104, 130, 127]]], dtype=uint8), array([[[195, 166, 150],\n",
      "        [179, 147, 134],\n",
      "        [191, 155, 143],\n",
      "        ..., \n",
      "        [ 35,  42,  61],\n",
      "        [ 42,  48,  70],\n",
      "        [ 47,  53,  77]],\n",
      "\n",
      "       [[182, 154, 140],\n",
      "        [170, 140, 129],\n",
      "        [178, 144, 134],\n",
      "        ..., \n",
      "        [ 36,  43,  62],\n",
      "        [ 43,  49,  71],\n",
      "        [ 49,  55,  79]],\n",
      "\n",
      "       [[168, 144, 132],\n",
      "        [167, 140, 129],\n",
      "        [172, 143, 135],\n",
      "        ..., \n",
      "        [ 37,  44,  63],\n",
      "        [ 44,  50,  72],\n",
      "        [ 49,  55,  79]],\n",
      "\n",
      "       ..., \n",
      "       [[ 30,  33,  26],\n",
      "        [ 19,  21,  16],\n",
      "        [ 45,  47,  46],\n",
      "        ..., \n",
      "        [ 23,  23,  25],\n",
      "        [ 17,  17,  19],\n",
      "        [  2,   2,   4]],\n",
      "\n",
      "       [[ 26,  29,  22],\n",
      "        [ 23,  25,  20],\n",
      "        [ 35,  37,  36],\n",
      "        ..., \n",
      "        [ 16,  16,  18],\n",
      "        [  9,   9,  11],\n",
      "        [  4,   4,   6]],\n",
      "\n",
      "       [[ 15,  18,  11],\n",
      "        [ 29,  31,  26],\n",
      "        [ 38,  40,  39],\n",
      "        ..., \n",
      "        [ 12,  12,  14],\n",
      "        [  8,   8,  10],\n",
      "        [ 11,  11,  13]]], dtype=uint8), array([[[246, 251, 244],\n",
      "        [252, 255, 251],\n",
      "        [252, 255, 251],\n",
      "        ..., \n",
      "        [101,  81,  80],\n",
      "        [ 87,  67,  69],\n",
      "        [ 80,  59,  64]],\n",
      "\n",
      "       [[249, 254, 247],\n",
      "        [250, 255, 249],\n",
      "        [250, 255, 249],\n",
      "        ..., \n",
      "        [ 87,  72,  69],\n",
      "        [ 79,  63,  63],\n",
      "        [ 75,  59,  60]],\n",
      "\n",
      "       [[253, 255, 250],\n",
      "        [248, 253, 247],\n",
      "        [247, 252, 248],\n",
      "        ..., \n",
      "        [ 67,  58,  51],\n",
      "        [ 67,  58,  53],\n",
      "        [ 70,  60,  58]],\n",
      "\n",
      "       ..., \n",
      "       [[ 57,  56,  70],\n",
      "        [ 51,  50,  64],\n",
      "        [ 51,  50,  64],\n",
      "        ..., \n",
      "        [167, 184, 113],\n",
      "        [166, 183, 112],\n",
      "        [165, 182, 111]],\n",
      "\n",
      "       [[ 49,  48,  62],\n",
      "        [ 44,  43,  57],\n",
      "        [ 46,  45,  59],\n",
      "        ..., \n",
      "        [167, 184, 113],\n",
      "        [166, 183, 112],\n",
      "        [165, 182, 111]],\n",
      "\n",
      "       [[ 41,  40,  54],\n",
      "        [ 37,  36,  50],\n",
      "        [ 41,  40,  54],\n",
      "        ..., \n",
      "        [168, 186, 112],\n",
      "        [166, 184, 110],\n",
      "        [165, 183, 109]]], dtype=uint8), array([[[ 96, 102, 114],\n",
      "        [113, 119, 131],\n",
      "        [132, 138, 150],\n",
      "        ..., \n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245]],\n",
      "\n",
      "       [[160, 166, 178],\n",
      "        [102, 108, 120],\n",
      "        [174, 180, 192],\n",
      "        ..., \n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245]],\n",
      "\n",
      "       [[195, 201, 213],\n",
      "        [180, 186, 198],\n",
      "        [240, 246, 255],\n",
      "        ..., \n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245],\n",
      "        [224, 237, 245]],\n",
      "\n",
      "       ..., \n",
      "       [[184, 186, 185],\n",
      "        [190, 192, 191],\n",
      "        [195, 197, 196],\n",
      "        ..., \n",
      "        [192, 190, 191],\n",
      "        [189, 187, 188],\n",
      "        [188, 186, 187]],\n",
      "\n",
      "       [[191, 193, 192],\n",
      "        [196, 198, 197],\n",
      "        [197, 199, 198],\n",
      "        ..., \n",
      "        [194, 190, 191],\n",
      "        [189, 185, 186],\n",
      "        [185, 181, 182]],\n",
      "\n",
      "       [[183, 185, 184],\n",
      "        [188, 190, 189],\n",
      "        [188, 190, 189],\n",
      "        ..., \n",
      "        [196, 192, 193],\n",
      "        [190, 186, 187],\n",
      "        [184, 180, 181]]], dtype=uint8), array([[143, 143, 143, ...,  90,  86,  89],\n",
      "       [143, 143, 143, ...,  90,  86,  89],\n",
      "       [143, 143, 143, ...,  90,  86,  89],\n",
      "       ..., \n",
      "       [214, 214, 214, ..., 139, 172, 104],\n",
      "       [214, 214, 214, ..., 139, 172, 104],\n",
      "       [214, 214, 214, ..., 139, 172, 104]], dtype=uint8), array([[  1,   0,   0, ...,   7,   8,   9],\n",
      "       [  0,   0,   0, ...,   6,   5,   4],\n",
      "       [  6,   6,   5, ...,   9,   6,   2],\n",
      "       ..., \n",
      "       [ 54,  54,  60, ..., 188, 168, 175],\n",
      "       [ 49,  47,  54, ..., 178, 161, 170],\n",
      "       [ 58,  55,  61, ..., 163, 156, 159]], dtype=uint8), array([[[ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        ..., \n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181]],\n",
      "\n",
      "       [[ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        ..., \n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181]],\n",
      "\n",
      "       [[ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        [ 95,  70,  48],\n",
      "        ..., \n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181],\n",
      "        [237, 219, 181]],\n",
      "\n",
      "       ..., \n",
      "       [[136, 126,  77],\n",
      "        [136, 126,  77],\n",
      "        [136, 126,  77],\n",
      "        ..., \n",
      "        [135, 132,  89],\n",
      "        [135, 132,  89],\n",
      "        [135, 132,  89]],\n",
      "\n",
      "       [[137, 125,  75],\n",
      "        [137, 125,  75],\n",
      "        [137, 125,  75],\n",
      "        ..., \n",
      "        [137, 134,  91],\n",
      "        [137, 134,  91],\n",
      "        [137, 134,  91]],\n",
      "\n",
      "       [[139, 127,  75],\n",
      "        [139, 127,  75],\n",
      "        [139, 127,  75],\n",
      "        ..., \n",
      "        [135, 132,  87],\n",
      "        [135, 132,  87],\n",
      "        [135, 132,  87]]], dtype=uint8), array([[[253, 242, 238],\n",
      "        [251, 240, 236],\n",
      "        [249, 238, 234],\n",
      "        ..., \n",
      "        [241, 232, 227],\n",
      "        [241, 232, 227],\n",
      "        [241, 232, 227]],\n",
      "\n",
      "       [[253, 242, 238],\n",
      "        [251, 240, 236],\n",
      "        [249, 238, 234],\n",
      "        ..., \n",
      "        [241, 232, 227],\n",
      "        [241, 232, 227],\n",
      "        [242, 233, 228]],\n",
      "\n",
      "       [[252, 241, 237],\n",
      "        [250, 239, 235],\n",
      "        [248, 237, 233],\n",
      "        ..., \n",
      "        [242, 233, 228],\n",
      "        [242, 233, 228],\n",
      "        [242, 233, 228]],\n",
      "\n",
      "       ..., \n",
      "       [[249, 250, 242],\n",
      "        [251, 251, 243],\n",
      "        [251, 251, 243],\n",
      "        ..., \n",
      "        [246, 236, 227],\n",
      "        [248, 238, 229],\n",
      "        [249, 239, 230]],\n",
      "\n",
      "       [[249, 250, 242],\n",
      "        [250, 250, 242],\n",
      "        [251, 251, 243],\n",
      "        ..., \n",
      "        [245, 235, 226],\n",
      "        [247, 237, 228],\n",
      "        [248, 238, 229]],\n",
      "\n",
      "       [[249, 250, 242],\n",
      "        [250, 250, 242],\n",
      "        [251, 251, 243],\n",
      "        ..., \n",
      "        [244, 234, 225],\n",
      "        [246, 236, 227],\n",
      "        [247, 237, 228]]], dtype=uint8), array([[[ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        ..., \n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126]],\n",
      "\n",
      "       [[ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        ..., \n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126]],\n",
      "\n",
      "       [[ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        [ 78, 100, 124],\n",
      "        ..., \n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126],\n",
      "        [ 93, 112, 126]],\n",
      "\n",
      "       ..., \n",
      "       [[139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        ..., \n",
      "        [110, 196, 255],\n",
      "        [110, 196, 255],\n",
      "        [111, 197, 255]],\n",
      "\n",
      "       [[139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        ..., \n",
      "        [110, 196, 255],\n",
      "        [110, 196, 255],\n",
      "        [111, 197, 255]],\n",
      "\n",
      "       [[139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        [139, 143, 155],\n",
      "        ..., \n",
      "        [110, 196, 255],\n",
      "        [110, 196, 255],\n",
      "        [111, 197, 255]]], dtype=uint8), array([[[ 51,  12,  13],\n",
      "        [ 51,  12,  13],\n",
      "        [ 60,  21,  22],\n",
      "        ..., \n",
      "        [122,  79,  26],\n",
      "        [121,  80,  28],\n",
      "        [121,  80,  28]],\n",
      "\n",
      "       [[ 59,  23,  23],\n",
      "        [ 51,  15,  15],\n",
      "        [ 54,  18,  18],\n",
      "        ..., \n",
      "        [122,  79,  26],\n",
      "        [121,  80,  28],\n",
      "        [121,  80,  28]],\n",
      "\n",
      "       [[ 50,  19,  17],\n",
      "        [ 47,  16,  14],\n",
      "        [ 53,  22,  20],\n",
      "        ..., \n",
      "        [122,  79,  26],\n",
      "        [121,  80,  28],\n",
      "        [121,  80,  28]],\n",
      "\n",
      "       ..., \n",
      "       [[  4,   8,  11],\n",
      "        [  4,   8,  11],\n",
      "        [  4,   8,  11],\n",
      "        ..., \n",
      "        [  6,   8,   7],\n",
      "        [  3,   5,   4],\n",
      "        [  2,   4,   3]],\n",
      "\n",
      "       [[  4,   8,  11],\n",
      "        [  4,   8,  11],\n",
      "        [  4,   8,  11],\n",
      "        ..., \n",
      "        [  2,   4,   3],\n",
      "        [  1,   3,   2],\n",
      "        [  1,   3,   2]],\n",
      "\n",
      "       [[  6,  10,  13],\n",
      "        [  5,   9,  12],\n",
      "        [  5,   9,  12],\n",
      "        ..., \n",
      "        [  0,   1,   0],\n",
      "        [  0,   1,   0],\n",
      "        [  0,   2,   1]]], dtype=uint8), array([[[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]],\n",
      "\n",
      "       ..., \n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]],\n",
      "\n",
      "       [[255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        [255, 255, 255],\n",
      "        ..., \n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119],\n",
      "        [119, 119, 119]]], dtype=uint8), array([[[187, 198, 190],\n",
      "        [188, 199, 191],\n",
      "        [193, 203, 195],\n",
      "        ..., \n",
      "        [240, 241, 236],\n",
      "        [233, 234, 229],\n",
      "        [228, 229, 224]],\n",
      "\n",
      "       [[190, 201, 193],\n",
      "        [191, 201, 193],\n",
      "        [195, 205, 197],\n",
      "        ..., \n",
      "        [239, 239, 237],\n",
      "        [233, 233, 231],\n",
      "        [228, 228, 226]],\n",
      "\n",
      "       [[194, 204, 195],\n",
      "        [194, 204, 195],\n",
      "        [196, 206, 197],\n",
      "        ..., \n",
      "        [238, 238, 236],\n",
      "        [232, 232, 230],\n",
      "        [228, 228, 226]],\n",
      "\n",
      "       ..., \n",
      "       [[ 47,  70,  78],\n",
      "        [ 44,  67,  75],\n",
      "        [ 43,  63,  72],\n",
      "        ..., \n",
      "        [ 41,  56,  51],\n",
      "        [ 21,  36,  31],\n",
      "        [  2,  17,  12]],\n",
      "\n",
      "       [[ 40,  63,  69],\n",
      "        [ 42,  65,  71],\n",
      "        [ 40,  63,  69],\n",
      "        ..., \n",
      "        [ 21,  36,  31],\n",
      "        [ 35,  50,  45],\n",
      "        [ 46,  61,  56]],\n",
      "\n",
      "       [[ 28,  53,  58],\n",
      "        [ 35,  58,  64],\n",
      "        [ 35,  58,  64],\n",
      "        ..., \n",
      "        [ 29,  44,  39],\n",
      "        [ 27,  42,  37],\n",
      "        [ 19,  34,  29]]], dtype=uint8), array([[[127, 100,  81],\n",
      "        [138, 111,  90],\n",
      "        [146, 118,  94],\n",
      "        ..., \n",
      "        [121,  92,  78],\n",
      "        [126,  94,  83],\n",
      "        [125,  91,  81]],\n",
      "\n",
      "       [[125, 100,  80],\n",
      "        [126,  99,  78],\n",
      "        [130, 104,  79],\n",
      "        ..., \n",
      "        [121,  93,  79],\n",
      "        [129,  99,  88],\n",
      "        [133, 101,  90]],\n",
      "\n",
      "       [[125, 103,  82],\n",
      "        [120,  95,  73],\n",
      "        [127, 103,  77],\n",
      "        ..., \n",
      "        [124,  98,  81],\n",
      "        [135, 107,  93],\n",
      "        [140, 111,  97]],\n",
      "\n",
      "       ..., \n",
      "       [[ 38,  63, 143],\n",
      "        [ 30,  55, 135],\n",
      "        [ 26,  51, 131],\n",
      "        ..., \n",
      "        [212,  72, 109],\n",
      "        [219,  78, 120],\n",
      "        [217,  76, 119]],\n",
      "\n",
      "       [[ 38,  63, 143],\n",
      "        [ 30,  55, 135],\n",
      "        [ 26,  51, 131],\n",
      "        ..., \n",
      "        [216,  69, 111],\n",
      "        [223,  76, 121],\n",
      "        [223,  73, 121]],\n",
      "\n",
      "       [[ 38,  63, 143],\n",
      "        [ 30,  55, 135],\n",
      "        [ 26,  51, 131],\n",
      "        ..., \n",
      "        [218,  69, 111],\n",
      "        [226,  74, 121],\n",
      "        [225,  71, 121]]], dtype=uint8), array([[[ 42,  56,  31],\n",
      "        [ 31,  48,  16],\n",
      "        [ 32,  50,   8],\n",
      "        ..., \n",
      "        [196, 195, 203],\n",
      "        [197, 196, 204],\n",
      "        [197, 196, 204]],\n",
      "\n",
      "       [[ 11,  28,   0],\n",
      "        [ 22,  40,   0],\n",
      "        [ 32,  52,   3],\n",
      "        ..., \n",
      "        [197, 196, 202],\n",
      "        [197, 196, 204],\n",
      "        [198, 197, 205]],\n",
      "\n",
      "       [[ 12,  32,   0],\n",
      "        [ 47,  67,  14],\n",
      "        [ 60,  82,  20],\n",
      "        ..., \n",
      "        [198, 197, 203],\n",
      "        [198, 197, 203],\n",
      "        [199, 198, 206]],\n",
      "\n",
      "       ..., \n",
      "       [[  0,  31, 134],\n",
      "        [  0,  30, 137],\n",
      "        [  0,  36, 149],\n",
      "        ..., \n",
      "        [ 31,  86, 213],\n",
      "        [ 32,  87, 213],\n",
      "        [ 30,  86, 209]],\n",
      "\n",
      "       [[  0,  29, 131],\n",
      "        [  0,  28, 133],\n",
      "        [  0,  34, 145],\n",
      "        ..., \n",
      "        [ 33,  88, 215],\n",
      "        [ 35,  90, 216],\n",
      "        [ 32,  88, 211]],\n",
      "\n",
      "       [[  0,  29, 131],\n",
      "        [  0,  28, 133],\n",
      "        [  0,  33, 144],\n",
      "        ..., \n",
      "        [ 34,  89, 216],\n",
      "        [ 36,  91, 217],\n",
      "        [ 34,  90, 213]]], dtype=uint8), array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ..., \n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)]\n",
      "[67, 27, 46, 43, 48, 38, 29, 25, 68, 60, 35, 64, 25, 19, 42, 1, 51, 20, 25, 33]\n"
     ]
    }
   ],
   "source": [
    "folderName = '/Users/mbk/desktop/wiki_crop/' \n",
    "fileNames = glob.glob(folderName +'*_resized/*.jpg')\n",
    "# only test 20 files for now\n",
    "NumberOfFileToBetested = 20\n",
    "\n",
    "x_values, y_values = convertToNumpy(fileNames[:NumberOfFileToBetested])\n",
    "\n",
    "print x_values\n",
    "print y_values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[209, 211, 210],\n",
       "        [210, 212, 211],\n",
       "        [204, 206, 205],\n",
       "        ..., \n",
       "        [180, 180, 180],\n",
       "        [146, 146, 146],\n",
       "        [143, 143, 143]],\n",
       "\n",
       "       [[210, 212, 211],\n",
       "        [217, 219, 218],\n",
       "        [215, 217, 216],\n",
       "        ..., \n",
       "        [126, 126, 126],\n",
       "        [126, 126, 126],\n",
       "        [115, 115, 115]],\n",
       "\n",
       "       [[212, 214, 213],\n",
       "        [223, 225, 224],\n",
       "        [225, 227, 226],\n",
       "        ..., \n",
       "        [124, 124, 124],\n",
       "        [135, 135, 135],\n",
       "        [122, 122, 122]],\n",
       "\n",
       "       ..., \n",
       "       [[121, 120, 125],\n",
       "        [124, 123, 128],\n",
       "        [146, 146, 148],\n",
       "        ..., \n",
       "        [122, 120, 121],\n",
       "        [127, 125, 126],\n",
       "        [126, 124, 125]],\n",
       "\n",
       "       [[134, 133, 138],\n",
       "        [162, 161, 166],\n",
       "        [200, 200, 202],\n",
       "        ..., \n",
       "        [147, 145, 146],\n",
       "        [135, 133, 134],\n",
       "        [115, 113, 114]],\n",
       "\n",
       "       [[135, 134, 139],\n",
       "        [155, 154, 159],\n",
       "        [158, 158, 160],\n",
       "        ..., \n",
       "        [196, 194, 195],\n",
       "        [164, 162, 163],\n",
       "        [119, 117, 118]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([209, 211, 210, ..., 119, 117, 118], dtype=uint8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(x_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flattened = [ np.ravel(matrices) for matrices in x_values ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([209, 211, 210, ..., 119, 117, 118], dtype=uint8),\n",
       " array([115,  34,  43, ...,  57, 126,  72], dtype=uint8),\n",
       " array([ 36,  26,  25, ..., 238, 176, 165], dtype=uint8),\n",
       " array([251, 251, 251, ...,   4,   4,   4], dtype=uint8),\n",
       " array([171, 145, 108, ...,  79,  85, 101], dtype=uint8),\n",
       " array([ 83,  94,  77, ..., 104, 130, 127], dtype=uint8),\n",
       " array([195, 166, 150, ...,  11,  11,  13], dtype=uint8),\n",
       " array([246, 251, 244, ..., 165, 183, 109], dtype=uint8),\n",
       " array([ 96, 102, 114, ..., 184, 180, 181], dtype=uint8),\n",
       " array([143, 143, 143, ..., 139, 172, 104], dtype=uint8),\n",
       " array([  1,   0,   0, ..., 163, 156, 159], dtype=uint8),\n",
       " array([ 95,  70,  48, ..., 135, 132,  87], dtype=uint8),\n",
       " array([253, 242, 238, ..., 247, 237, 228], dtype=uint8),\n",
       " array([ 78, 100, 124, ..., 111, 197, 255], dtype=uint8),\n",
       " array([51, 12, 13, ...,  0,  2,  1], dtype=uint8),\n",
       " array([255, 255, 255, ..., 119, 119, 119], dtype=uint8),\n",
       " array([187, 198, 190, ...,  19,  34,  29], dtype=uint8),\n",
       " array([127, 100,  81, ..., 225,  71, 121], dtype=uint8),\n",
       " array([ 42,  56,  31, ...,  34,  90, 213], dtype=uint8),\n",
       " array([0, 0, 0, ..., 0, 0, 0], dtype=uint8)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create rdd of flattened values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flat_rdd = sc.parallelize(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_rdd.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create rdd of the corresponding age values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "age_rdd = sc.parallelize(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[67, 27, 46, 43, 48, 38, 29, 25, 68, 60, 35, 64, 25, 19, 42, 1, 51, 20, 25, 33]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age_rdd.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combined RDD of pixels and the age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([209, 211, 210, ..., 119, 117, 118], dtype=uint8), 67),\n",
       " (array([115,  34,  43, ...,  57, 126,  72], dtype=uint8), 27),\n",
       " (array([ 36,  26,  25, ..., 238, 176, 165], dtype=uint8), 46),\n",
       " (array([251, 251, 251, ...,   4,   4,   4], dtype=uint8), 43),\n",
       " (array([171, 145, 108, ...,  79,  85, 101], dtype=uint8), 48),\n",
       " (array([ 83,  94,  77, ..., 104, 130, 127], dtype=uint8), 38),\n",
       " (array([195, 166, 150, ...,  11,  11,  13], dtype=uint8), 29),\n",
       " (array([246, 251, 244, ..., 165, 183, 109], dtype=uint8), 25),\n",
       " (array([ 96, 102, 114, ..., 184, 180, 181], dtype=uint8), 68),\n",
       " (array([143, 143, 143, ..., 139, 172, 104], dtype=uint8), 60),\n",
       " (array([  1,   0,   0, ..., 163, 156, 159], dtype=uint8), 35),\n",
       " (array([ 95,  70,  48, ..., 135, 132,  87], dtype=uint8), 64),\n",
       " (array([253, 242, 238, ..., 247, 237, 228], dtype=uint8), 25),\n",
       " (array([ 78, 100, 124, ..., 111, 197, 255], dtype=uint8), 19),\n",
       " (array([51, 12, 13, ...,  0,  2,  1], dtype=uint8), 42),\n",
       " (array([255, 255, 255, ..., 119, 119, 119], dtype=uint8), 1),\n",
       " (array([187, 198, 190, ...,  19,  34,  29], dtype=uint8), 51),\n",
       " (array([127, 100,  81, ..., 225,  71, 121], dtype=uint8), 20),\n",
       " (array([ 42,  56,  31, ...,  34,  90, 213], dtype=uint8), 25),\n",
       " (array([0, 0, 0, ..., 0, 0, 0], dtype=uint8), 33)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = flat_rdd.zip(age_rdd)\n",
    "combined.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a dataframe using createDataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "postSchema = StructType([\n",
    "  StructField(\"feature\", ArrayType(IntegerType())),\n",
    "  StructField(\"label\", IntegerType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imageRDD = sqlContext.createDataFrame(combined, postSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o111.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 13, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/session.py\", line 520, in prepare\n    verify_func(obj, schema)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1360, in _verify_type\n    _verify_type(v, f.dataType, f.nullable)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1324, in _verify_type\n    raise TypeError(\"%s can not accept object %r in type %s\" % (dataType, obj, type(obj)))\nTypeError: ArrayType(IntegerType,true) can not accept object array([209, 211, 210, ..., 119, 117, 118], dtype=uint8) in type <type 'numpy.ndarray'>\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:2853)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$55.apply(Dataset.scala:2837)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:2836)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2366)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:245)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/session.py\", line 520, in prepare\n    verify_func(obj, schema)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1360, in _verify_type\n    _verify_type(v, f.dataType, f.nullable)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1324, in _verify_type\n    raise TypeError(\"%s can not accept object %r in type %s\" % (dataType, obj, type(obj)))\nTypeError: ArrayType(IntegerType,true) can not accept object array([209, 211, 210, ..., 119, 117, 118], dtype=uint8) in type <type 'numpy.ndarray'>\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1751d395e96c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimageRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/dataframe.pyc\u001b[0m in \u001b[0;36mshow\u001b[0;34m(self, n, truncate)\u001b[0m\n\u001b[1;32m    334\u001b[0m         \"\"\"\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 336\u001b[0;31m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    337\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtruncate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o111.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 4.0 failed 1 times, most recent failure: Lost task 0.0 in stage 4.0 (TID 13, localhost, executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/session.py\", line 520, in prepare\n    verify_func(obj, schema)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1360, in _verify_type\n    _verify_type(v, f.dataType, f.nullable)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1324, in _verify_type\n    raise TypeError(\"%s can not accept object %r in type %s\" % (dataType, obj, type(obj)))\nTypeError: ArrayType(IntegerType,true) can not accept object array([209, 211, 210, ..., 119, 117, 118], dtype=uint8) in type <type 'numpy.ndarray'>\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\n\tat scala.Option.foreach(Option.scala:257)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\n\tat org.apache.spark.sql.execution.SparkPlan.executeTake(SparkPlan.scala:336)\n\tat org.apache.spark.sql.execution.CollectLimitExec.executeCollect(limit.scala:38)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$collectFromPlan(Dataset.scala:2853)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$head$1.apply(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset$$anonfun$55.apply(Dataset.scala:2837)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:65)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:2836)\n\tat org.apache.spark.sql.Dataset.head(Dataset.scala:2153)\n\tat org.apache.spark.sql.Dataset.take(Dataset.scala:2366)\n\tat org.apache.spark.sql.Dataset.showString(Dataset.scala:245)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 177, in main\n    process()\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/worker.py\", line 172, in process\n    serializer.dump_stream(func(split_index, iterator), outfile)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/serializers.py\", line 268, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/session.py\", line 520, in prepare\n    verify_func(obj, schema)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1360, in _verify_type\n    _verify_type(v, f.dataType, f.nullable)\n  File \"/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1324, in _verify_type\n    raise TypeError(\"%s can not accept object %r in type %s\" % (dataType, obj, type(obj)))\nTypeError: ArrayType(IntegerType,true) can not accept object array([209, 211, 210, ..., 119, 117, 118], dtype=uint8) in type <type 'numpy.ndarray'>\n\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)\n\tat org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)\n\tat org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)\n\tat org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:323)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:287)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:87)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "imageRDD.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using toDF() instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[209, 211, 210, 2...|   67|\n",
      "|[115, 34, 43, 110...|   27|\n",
      "|[36, 26, 25, 36, ...|   46|\n",
      "|[251, 251, 251, 2...|   43|\n",
      "|[171, 145, 108, 1...|   48|\n",
      "|[83, 94, 77, 83, ...|   38|\n",
      "|[195, 166, 150, 1...|   29|\n",
      "|[246, 251, 244, 2...|   25|\n",
      "|[96, 102, 114, 11...|   68|\n",
      "|[143, 143, 143, 1...|   60|\n",
      "|[1, 0, 0, 0, 0, 0...|   35|\n",
      "|[95, 70, 48, 95, ...|   64|\n",
      "|[253, 242, 238, 2...|   25|\n",
      "|[78, 100, 124, 78...|   19|\n",
      "|[51, 12, 13, 51, ...|   42|\n",
      "|[255, 255, 255, 2...|    1|\n",
      "|[187, 198, 190, 1...|   51|\n",
      "|[127, 100, 81, 13...|   20|\n",
      "|[42, 56, 31, 31, ...|   25|\n",
      "|[0, 0, 0, 0, 0, 0...|   33|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = combined.map(lambda x: ( x[0].tolist(), (x[1]))).toDF([\"features\",\"label\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train, df_test = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[36, 26, 25, 36, ...|   46|\n",
      "|[171, 145, 108, 1...|   48|\n",
      "|[83, 94, 77, 83, ...|   38|\n",
      "|[96, 102, 114, 11...|   68|\n",
      "|[143, 143, 143, 1...|   60|\n",
      "|[195, 166, 150, 1...|   29|\n",
      "|[1, 0, 0, 0, 0, 0...|   35|\n",
      "|[51, 12, 13, 51, ...|   42|\n",
      "|[78, 100, 124, 78...|   19|\n",
      "|[95, 70, 48, 95, ...|   64|\n",
      "|[253, 242, 238, 2...|   25|\n",
      "|[0, 0, 0, 0, 0, 0...|   33|\n",
      "|[42, 56, 31, 31, ...|   25|\n",
      "|[127, 100, 81, 13...|   20|\n",
      "|[187, 198, 190, 1...|   51|\n",
      "|[255, 255, 255, 2...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[115, 34, 43, 110...|   27|\n",
      "|[209, 211, 210, 2...|   67|\n",
      "|[251, 251, 251, 2...|   43|\n",
      "|[246, 251, 244, 2...|   25|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_test.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### try logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'Data type ArrayType(LongType,true) is not supported.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-461721278156>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mva_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mva_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVectorAssembler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputCols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mva_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mva_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/base.pyc\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Params must be a param map but got %s.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_transform\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: u'Data type ArrayType(LongType,true) is not supported.'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "va_train = VectorAssembler(outputCol=\"features\", inputCols=df_train.columns[0:-1])\n",
    "va_test = VectorAssembler(outputCol=\"features\", inputCols=df_test.columns[0:-1])\n",
    "train = va_train.transform(df_train).select(\"features\", \"label\").cache()\n",
    "test = va_test.transform(df_test).select(\"features\", \"label\").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'requirement failed: Column features must be of type org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7 but was actually ArrayType(LongType,true).'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-8a54d2cc0246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxIter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melasticNetParam\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlrModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \"\"\"\n\u001b[1;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/apache-spark/2.2.0/libexec/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: u'requirement failed: Column features must be of type org.apache.spark.ml.linalg.VectorUDT@3bfc3ba7 but was actually ArrayType(LongType,true).'"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lrModel = lr.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
